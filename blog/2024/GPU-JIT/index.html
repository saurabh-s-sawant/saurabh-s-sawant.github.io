<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Just-In-Time Compiled CUDA Kernel | Saurabh S. Sawant </title> <meta name="author" content="Saurabh S. Sawant"> <meta name="description" content="Using NVRTC library to compile a CUDA kernel just-in-time, allowing you to dynamically adjust compiler settings based on run-time conditions."> <meta name="keywords" content="saurabh-s-sawant, saurabh-sawant, portfolio, website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://saurabh-s-sawant.github.io/blog/2024/GPU-JIT/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Saurabh </span> S.  Sawant </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Research </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Just-In-Time Compiled CUDA Kernel</h1> <p class="post-meta"> May 20, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/gpu"> <i class="fa-solid fa-hashtag fa-sm"></i> gpu,</a>   <a href="/blog/tag/jit"> <i class="fa-solid fa-hashtag fa-sm"></i> JIT</a>     ·   <a href="/blog/category/code"> <i class="fa-solid fa-tag fa-sm"></i> code</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <h3 id="overview">Overview</h3> <p>Just-in-Time (JIT) compilation is a powerful tool for developers aiming to optimize applications dynamically. With this technique, compilation of the code can be deferred to runtime rather than ahead-of-time (AoT). Here I explore the use of NVIDIA’s NVRTC runtime compilation library to JIT-compile a simple CUDA kernel for vector addition. With this technique, we can alter CUDA code dynamically based on run-time conditions.</p> <h3 id="why-to-use-jit-in-cuda">Why to Use JIT in CUDA?</h3> <ul> <li>On-the-fly generation of CUDA kernels based on configuration at run-time</li> <li>Optimization of kernel for specific GPU architecture</li> <li>Testing without the overhead of recompiling the whole program after every change</li> </ul> <h3 id="exampple-vector-addition">Exampple: Vector Addition</h3> <p>Code is available at <a href="https://github.com/saurabh-s-sawant/gpu_exer/blob/main/practice_codes/jit_nvrtc/vector_add/vectorAdd_JIT.cu" rel="external nofollow noopener" target="_blank">vector_add_JIT.cu</a>. Major components of the code are described below.</p> <h4 id="kernel-code-as-string">Kernel code as string</h4> <p>NVRTC requires CUDA kernel written as string. Here is the simple kernel to add two vectors and store it in a third vector.</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">cudaKernelCode</span> <span class="o">=</span> <span class="s">R"(
extern "C"
__global__ void vectorAdd(const float* A, const float* B, float* C, int N) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx &lt; N) {
        C[idx] = A[idx] + B[idx];
    }
}
)"</span><span class="p">;</span>
</code></pre></div></div> <h4 id="compilation">Compilation</h4> <p>Compile the kernel using NVRTC. <code class="language-plaintext highlighter-rouge">options</code> is a vector that reads in the compilation flags passed as arguments at run-time.</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="c1">// Use NVRTC to compile the kernel</span>
    <span class="n">nvrtcProgram</span> <span class="n">prog</span><span class="p">;</span>
    <span class="n">NVRTC_SAFE_CALL</span><span class="p">(</span><span class="n">nvrtcCreateProgram</span><span class="p">(</span><span class="o">&amp;</span><span class="n">prog</span><span class="p">,</span> <span class="n">cudaKernelCode</span><span class="p">,</span> <span class="s">"vectorAdd.cu"</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">));</span>

    <span class="c1">// Compile the kernel</span>
    <span class="n">nvrtcResult</span> <span class="n">compileResult</span> <span class="o">=</span> <span class="n">nvrtcCompileProgram</span><span class="p">(</span><span class="n">prog</span><span class="p">,</span> <span class="n">options</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">options</span><span class="p">.</span><span class="n">data</span><span class="p">());</span>
</code></pre></div></div> <h4 id="generation-of-ptx">Generation of PTX</h4> <p>Generate PTX code. Optionally, write it to a file for analysis.</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="c1">// Obtain the PTX from the program</span>
    <span class="kt">size_t</span> <span class="n">ptxSize</span><span class="p">;</span>
    <span class="n">NVRTC_SAFE_CALL</span><span class="p">(</span><span class="n">nvrtcGetPTXSize</span><span class="p">(</span><span class="n">prog</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">ptxSize</span><span class="p">));</span>
    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">char</span><span class="o">&gt;</span> <span class="n">ptx</span><span class="p">(</span><span class="n">ptxSize</span><span class="p">);</span>
    <span class="n">NVRTC_SAFE_CALL</span><span class="p">(</span><span class="n">nvrtcGetPTX</span><span class="p">(</span><span class="n">prog</span><span class="p">,</span> <span class="n">ptx</span><span class="p">.</span><span class="n">data</span><span class="p">()));</span>

    <span class="c1">//...</span>

    <span class="n">ptxFile</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">ptx</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">ptx</span><span class="p">.</span><span class="n">size</span><span class="p">());</span>
</code></pre></div></div> <h4 id="execution">Execution</h4> <p>Load the compiled kernel and execute it on GPU.</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="c1">// Load the PTX and get the kernel handle</span>
    <span class="n">CUmodule</span> <span class="k">module</span><span class="p">;</span>
    <span class="n">CUfunction</span> <span class="n">kernel</span><span class="p">;</span>
    <span class="n">CU_SAFE_CALL</span><span class="p">(</span><span class="n">cuModuleLoadData</span><span class="p">(</span><span class="o">&amp;</span><span class="k">module</span><span class="p">,</span> <span class="n">ptx</span><span class="p">.</span><span class="n">data</span><span class="p">()));</span>
    <span class="n">CU_SAFE_CALL</span><span class="p">(</span><span class="n">cuModuleGetFunction</span><span class="p">(</span><span class="o">&amp;</span><span class="n">kernel</span><span class="p">,</span> <span class="k">module</span><span class="p">,</span> <span class="s">"vectorAdd"</span><span class="p">));</span>

    <span class="c1">// Launch the kernel</span>
    <span class="kt">void</span><span class="o">*</span> <span class="n">args</span><span class="p">[]</span> <span class="o">=</span> <span class="p">{</span> <span class="o">&amp;</span><span class="n">d_A</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">d_B</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">d_C</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">N</span> <span class="p">};</span>
    <span class="kt">int</span> <span class="n">threadsPerBlock</span> <span class="o">=</span> <span class="mi">256</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">blocksPerGrid</span> <span class="o">=</span> <span class="p">(</span><span class="n">N</span> <span class="o">+</span> <span class="n">threadsPerBlock</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">threadsPerBlock</span><span class="p">;</span>
    <span class="n">CU_SAFE_CALL</span><span class="p">(</span><span class="n">cuLaunchKernel</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">blocksPerGrid</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">threadsPerBlock</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="mi">0</span><span class="p">));</span>
</code></pre></div></div> <h4 id="compile-and-run">Compile and Run</h4> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nvcc vectorAdd_JIT.cu -o solver.x -lnvrtc -lcuda -std=c++14
</code></pre></div></div> <h3 id="analysis">Analysis</h3> <p>Let’s run the code with and without passing the argument <code class="language-plaintext highlighter-rouge">--use_fast_math</code> and compare whether the JIT-compiled code generates a different assembly code at run time. This flag replaces certain floating point operations with faster versions that may be less accurate for efficiency.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/gpu_jit/jit_ptx_diff-480.webp 480w,/assets/img/posts/gpu_jit/jit_ptx_diff-800.webp 800w,/assets/img/posts/gpu_jit/jit_ptx_diff-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/posts/gpu_jit/jit_ptx_diff.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <div align="justify"> Output of vimdiff command on ptx generated without (left) and with --use_fast_math flag (right). </div> </div> <p>From the figure above, we see the difference in assembly at an instruction where two floating points in <code class="language-plaintext highlighter-rouge">%f2</code> and <code class="language-plaintext highlighter-rouge">%f1</code> registers are added and stored in <code class="language-plaintext highlighter-rouge">%f3</code> register.</p> <p>The <code class="language-plaintext highlighter-rouge">ftz</code> qualifier stands for Flust To Zero, which affects how the instruction handles very small numbers close to zero, known as subnormal numbers. (When the result of a computation is too small to be represented as a normal floating-point number (given the constraints of the exponent and mantissa), it can be represented as a subnormal number. In subnormal numbers, the leading bit of the mantissa is zero instead of one, allowing for the representation of numbers closer to zero than would otherwise be possible. This is done at the cost of precision).</p> <p>The <code class="language-plaintext highlighter-rouge">ftz</code> mode ensures subnormal numbers are treated as zero, which may prevent performance penalties arising from handling denormalized numbers.</p> <h3 id="references">References</h3> <ul> <li><a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#driver-api" rel="external nofollow noopener" target="_blank">CUDA Driver API</a></li> <li><a href="https://en.wikipedia.org/wiki/Subnormal_number" rel="external nofollow noopener" target="_blank">Subnormal numbers</a></li> </ul> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/policyBasedDesign/">Exploring Policy-Based Design: A Customizable Message Logger in C++</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/typeErasure/">Exploring Type Erasure as a Design Pattern: A Generic Materials Solver</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/GPU/">GPU Practice Codes</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/TMP/">Template Metaprogramming Practice Codes</a> </li> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Saurabh S. Sawant. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>